{"cells":[{"metadata":{"_uuid":"935fe128-5e23-4b38-b4a0-93eaf5cb52c4","_cell_guid":"1acaaa46-a8f6-4575-8f8b-7fe60d8cbef7","trusted":true},"cell_type":"markdown","source":"## Import the necessary libraries"},{"metadata":{"_uuid":"29ff1c0e-85be-4b16-907c-e19669f6b161","_cell_guid":"00b64ceb-8828-4c34-a317-46d1d40e1a0b","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\nimport string\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nfrom sklearn.metrics import f1_score\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db969d2a-ce9c-42c3-a15d-7b19c9e31ea4","_cell_guid":"340d4e9d-3977-45f5-b692-1d4acc8a2b14","trusted":true},"cell_type":"markdown","source":"## Load in your data from kaggle.  \nBy working in a kaggle kernel, you can access the data directly from the competition, as well as make your submission without downloading your output file"},{"metadata":{"_uuid":"929e1a88-e9ec-44db-878c-9ef689cfa5db","_cell_guid":"886bb1e7-5d47-4e8c-af32-e1c44f64aa81","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/climate-change-edsa2020-21/train.csv')\ntest = pd.read_csv('../input/climate-change-edsa2020-21/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)\n\ndisplay(train.head())\ndisplay(test.head())\n\npercent_duplicates = round((1-(train['message'].nunique()/len(train['message'])))*100,2)\nprint('Duplicated tweets in train data:')\nprint(percent_duplicates,'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sentiment.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.isnull().sum())\nprint(test.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d1b45bf-8466-4c8d-a636-d9c2eee3fa41","_cell_guid":"629ad26f-0c51-4bea-84a3-816f82075531","trusted":true},"cell_type":"markdown","source":"## Splitting out the X variable from the target"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['sentiment']\nX = train['message']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pre-processing "},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessor(text):\n    \n    text = text.lower()\n    text = re.sub(re.sub(r'\\^[a-zA-Z]s+','', text))\n    text = re.sub(\"\\\\s+(in|the|all|for|and|on)\\\\s+\",\" _connector_ \",text)\n    \n    words = re.split(\"\\\\s+\", text)\n    stemmed_words = [porter_stemmer.stem(word=word) for word in words]\n    \n    return ''.join(stemmed_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def text_tokenizer(text):\n    #space between special characters \n    text = re.sub(\"(\\\\W)\",\"\\\\1\", text)\n                  \n    #split whitespace\n    return re.split(\"\\\\s+\", text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.isnull().sum())\nprint(test.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Turning text into something your model can read"},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=2, stop_words=\"english\")\nX_vectorized = vectorizer.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_vectorized)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30a5fc8a-db09-4059-8191-f6251100c9be","_cell_guid":"e0773c81-ad5d-41c5-9aa6-a50337a5aa18","trusted":true},"cell_type":"markdown","source":"## Splitting the training data into a training and validation set"},{"metadata":{"_uuid":"1cb597c3-785a-4052-9584-b881bfcc0b2a","_cell_guid":"b56790d8-6b77-4d29-b3e8-f702cf1aa2bf","trusted":true},"cell_type":"code","source":"X_train,X_val,y_train,y_val = train_test_split(X_vectorized,y,test_size=.3,shuffle=True, stratify=y, random_state=11)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the model and evaluating using the validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)\nrfc_pred = rfc.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lsvc = LinearSVC()\nlsvc.fit(X_train, y_train)\nlsvc_pred = lsvc.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nprint(metrics.classification_report(y_val, lsvc_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Getting our test set ready"},{"metadata":{"trusted":true},"cell_type":"code","source":"testx = test['message']\ntest_vect = vectorizer.transform(testx)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"202523a4-7bc7-4e20-b89d-3c06e5b3eb95","_cell_guid":"c5aa2c29-5fc9-4c2a-8b04-d2a260d9a81f","trusted":true},"cell_type":"markdown","source":"## Making predictions on the test set and adding a sentiment column to our original test df"},{"metadata":{"_uuid":"e980cd06-4e3d-4c91-a2b5-41697349210c","_cell_guid":"ab0c9b28-a6b7-4944-b9b2-b3803dbc1a7e","trusted":true},"cell_type":"code","source":"y_pred = lsvc.predict(test_vect)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6850c64d-d34b-4530-9e0c-ca969447fb24","_cell_guid":"260f6b19-bc6d-4357-93a6-c0d57b34a7da","trusted":true},"cell_type":"code","source":"test['sentiment'] = y_pred","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49d924cf-eb57-4311-adb1-74f8d8c66324","_cell_guid":"7f9f88d1-61d4-44f1-9dc8-e121a578b840","trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8f5492e-13d9-47f1-80a2-aef0a8ea4873","_cell_guid":"65160c52-daf9-4531-9c00-d0d1ff50257d","trusted":true},"cell_type":"markdown","source":"## Creating an output csv for submission"},{"metadata":{"_uuid":"05a356ae-591b-4168-8f1a-d40babc877a5","_cell_guid":"51285dcf-ace4-4d48-adf5-38b8e34b5fe3","trusted":true},"cell_type":"code","source":"test[['tweetid','sentiment']].to_csv('testsubmission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}